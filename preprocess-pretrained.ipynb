{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41188,
     "status": "ok",
     "timestamp": 1743112083023,
     "user": {
      "displayName": "Lencho Nedha",
      "userId": "16702485404824130438"
     },
     "user_tz": -180
    },
    "id": "LAGNQqBZPirB",
    "outputId": "cb8ef4d2-f98b-4223-97d9-4bc4b3069a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_xiQuaeP-vc"
   },
   "outputs": [],
   "source": [
    "!pip install chardet\n",
    "import chardet\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "  with open(file_path,\"rb\") as file:\n",
    "    raw_data=file.read()\n",
    "  result = chardet.detect(raw_data)\n",
    "  return result['encoding']\n",
    "def convert_to_utf8(input_file,output_file,source_encoding=None):\n",
    "  if not source_encoding:\n",
    "    source_encoding=detect_encoding(input_file)\n",
    "    print(f\"Detect encoding: {source_encoding}\")\n",
    "  with open(input_file,\"r\",encoding=source_encoding) as file:\n",
    "    text=file.read()\n",
    "  with open(output_file,\"w\",encoding=\"utf-8\") as file:\n",
    "    file.write(text)\n",
    "  print(f\"File Converted to UTF-8: {output_file}\")\n",
    "input_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "output_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "convert_to_utf8(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_0SdGPMQClE"
   },
   "outputs": [],
   "source": [
    "# remove HTML Tag, URL, emoji, change encode to utf-8\n",
    "def remove_html_tags(text):\n",
    "  clean_txt=re.compile(r\"<.*?>\") #match b/n  < and >\n",
    "  return re.sub(clean_txt,\"\",text)\n",
    "def remove_url(text):\n",
    "  clean_txt=re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "  return re.sub(clean_txt,\"\",text)\n",
    "def clean_txt_file(input_file,output_file=None):\n",
    "  #read file\n",
    "  with open(input_file,\"r\",encoding=\"utf-8\") as file:\n",
    "    txt=file.read()\n",
    "  txt=remove_html_tags(txt)\n",
    "  txt=remove_url(txt)\n",
    "  if not output_file:\n",
    "    with open(output_file,\"w\",encoding=\"utf-8\") as file:\n",
    "      file.write(txt)\n",
    "  return txt\n",
    "\n",
    "input_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "output_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "clean_txt_file(input_file,output_file)\n",
    "print(f\"Data is clean and saved successfully!: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ZnjrPxQFJj"
   },
   "outputs": [],
   "source": [
    "# remove emoji\n",
    "def remove_emojis(txt_file):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\"  # Enclosed Characters\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    # Use re.sub to remove emojis from the text\n",
    "    return re.sub(emoji_pattern, \"\", txt_file) #This line is changed to return cleaned text\n",
    "\n",
    "\n",
    "def clean_txt_file(input_file,output_file):\n",
    "  with open(input_file,\"r\",encoding=\"utf-8\") as file:\n",
    "    txt=file.read()\n",
    "  txt_cleaned=remove_emojis(txt)\n",
    "  with open(output_file,\"w\",encoding=\"utf-8\") as file:\n",
    "    file.write(txt_cleaned)\n",
    "  print(f\"Emoji is cleaned and Data saved successfully!: {output_file}\")\n",
    "input_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "output_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "clean_txt_file(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bw7O_qTEQMqE"
   },
   "outputs": [],
   "source": [
    "#Normaliza\n",
    "# remove special characters except hudha(') and . ?\n",
    "def normalize_txt(txt_file):\n",
    "  txt_file = re.sub(r\"[^a-zA-Z0-9\\s'.?]\", \"\", txt_file)\n",
    "    #txt_file = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "  return txt_file\n",
    "\n",
    "def clean_txt_file(input_file,output_file):\n",
    "  with open(input_file,\"r\",encoding=\"utf-8\") as file:\n",
    "    txt=file.read()\n",
    "  txt_cleaned=normalize_txt(txt)\n",
    "  with open(output_file,\"w\",encoding=\"utf-8\") as file:\n",
    "    file.write(txt_cleaned)\n",
    "  print(f\"Special characters are cleaned and Data saved successfully!: {output_file}\")\n",
    "\n",
    "input_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "output_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "clean_txt_file(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcfFfn5bQVgz"
   },
   "outputs": [],
   "source": [
    "# Count number of characters perline\n",
    "def count_characters_per_line(input_file):\n",
    "  char_count=[]\n",
    "  with open(input_file,\"r\",encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "      char_count.append(len(line))\n",
    "  return char_count\n",
    "input_file='/content/drive/MyDrive/Thesis_Work/PretrainData/afaanoromoo_pretrain_corpus.txt'\n",
    "char_count=count_characters_per_line(input_file)\n",
    "\n",
    "#display\n",
    "for i,count in enumerate(char_count):\n",
    "  print(f\"Line {i+1}: {count} characters\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
