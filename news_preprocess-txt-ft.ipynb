{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25781,
     "status": "ok",
     "timestamp": 1744899003073,
     "user": {
      "displayName": "Lencho Neda",
      "userId": "10571622500093309298"
     },
     "user_tz": -180
    },
    "id": "eOfR1c0GEDX9",
    "outputId": "4e52f84c-052b-4d06-f82f-38b8a09011e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1744899003864,
     "user": {
      "displayName": "Lencho Neda",
      "userId": "10571622500093309298"
     },
     "user_tz": -180
    },
    "id": "JQqxT8xJOo8z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1744898521024,
     "user": {
      "displayName": "Lencho Neda",
      "userId": "10571622500093309298"
     },
     "user_tz": -180
    },
    "id": "Zs6RyEpdDYdw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read with correct original encoding (common ones: 'utf-8', 'latin1', 'cp1252')\n",
    "df = pd.read_csv('/content/drive/MyDrive/AOBERT/Data_Cleaned/ethionewsdataset.csv', encoding='latin1')\n",
    "\n",
    "# Save with UTF-8\n",
    "df.to_csv('/content/drive/MyDrive/AOBERT/Data_Cleaned/ethionewsdataset11.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC86z21u5zn-"
   },
   "source": [
    "***Preprocess fine tune text-remove special character, URL, hashtag,punctuation, extra space, markup lang***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1308,
     "status": "ok",
     "timestamp": 1744899046746,
     "user": {
      "displayName": "Lencho Neda",
      "userId": "10571622500093309298"
     },
     "user_tz": -180
    },
    "id": "NNztdrJ6Np5F"
   },
   "outputs": [],
   "source": [
    "def preprocess_ft_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s']\", '', text)  # Remove special characters except apostrophes(hudhaa)\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)  # Remove hashtags\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)  # Remove punctuation and non-alphanumeric characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)  # Remove markup language\n",
    "    return text.strip()\n",
    "with open('/content/drive/MyDrive/AOBERT/Data_Cleaned/ethionewsdataset11.csv', 'r', encoding='latin-1') as infile, \\\n",
    "     open('/content/drive/MyDrive/AOBERT/Data_Cleaned/ethionewsdataset11a.csv', 'w', encoding='utf-8') as outfile:\n",
    "  reader = csv.reader(infile)\n",
    "  writer = csv.writer(outfile, delimiter='\\t')  # Using tab as delimiter for better readability in text file\n",
    "  for row in reader:\n",
    "    row[0]=preprocess_ft_text(row[0])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1744899058771,
     "user": {
      "displayName": "Lencho Neda",
      "userId": "10571622500093309298"
     },
     "user_tz": -180
    },
    "id": "LOOePfEs68Kt",
    "outputId": "eaf7b1f7-802b-4fae-9029-a037a57a4be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0      1\n",
      "0                                               text  label\n",
      "1  weellistuun beekamtuu ameerikaa biyoonseen wal...      0\n",
      "2  xiyyaarri imaltootaa raashiyaa erga girrisa si...      0\n",
      "3  raapparii fi taatoo beekamaan us dmx ganna 50t...      0\n",
      "4  simbirroonni masqalaa jioota hedduuf erga bada...      0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/AOBERT/Data_Cleaned/ethionewsdataset11a.csv', sep='\\t', header=None)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uIs8Dpd6T5d"
   },
   "source": [
    "***Remove Stop words***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4562,
     "status": "ok",
     "timestamp": 1744899095986,
     "user": {
      "displayName": "Lencho Neda",
      "userId": "10571622500093309298"
     },
     "user_tz": -180
    },
    "id": "QQjQF3q5rD2Y"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text, stop_words_file):\n",
    "    with open(stop_words_file, 'r') as f:\n",
    "        stop_words = set([line.strip() for line in f])\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "column_to_clean = 'text' #column containing AO emotional data\n",
    "with open('/content/drive/MyDrive/AOBERT/Data_Cleaned/ethionewsdataset11a.csv', 'r', encoding='utf-8') as infile, \\\n",
    "     open('/content/drive/MyDrive/AOBERT/Data_Cleaned/ethionewsdataset11ab.csv', 'w', encoding='utf-8') as outfile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    writer = csv.writer(outfile, delimiter='\\t')\n",
    "    header = next(reader)  # Read the header row\n",
    "    writer.writerow(header)  # Write the header to the output file\n",
    "\n",
    "    for row in reader:\n",
    "        # Get the index of the column to clean\n",
    "        try:\n",
    "            column_index = header.index(column_to_clean)\n",
    "        except ValueError:\n",
    "            print(f\"Column '{column_to_clean}' not found in header. Skipping row...\")\n",
    "            continue\n",
    "        # Clean the selected column\n",
    "        row[column_index] = remove_stop_words(row[column_index], '/content/drive/MyDrive/AOBERT_MODEL/ao_stop_words.txt')\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
